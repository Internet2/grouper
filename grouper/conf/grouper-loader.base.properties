#
# Copyright 2014 Internet2
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

########################################
## Config chaining hierarchy
## Grouper loader uses Grouper Configuration Overlays (documented on wiki)
## By default the configuration is read from grouper-loader.base.properties
## (which should not be edited), and the grouper-loader.properties overlays
## the base settings.  See the grouper-loader.base.properties for the possible
## settings that can be applied to the grouper.properties
########################################

# comma separated config files that override each other (files on the right override the left)
# each should start with file: or classpath:
# e.g. classpath:grouper-loader.example.properties, file:c:/something/myconfig.properties
# {valueType: "string", required: true, multiple: true}
loader.config.hierarchy = classpath:grouper-loader.base.properties, classpath:grouper-loader.properties, database:grouper

# seconds between checking to see if the config files are updated
# {valueType: "integer", required: true}
loader.config.secondsBetweenUpdateChecks = 60


########################################
## General settings
########################################


# auto-add grouper loader types and attributes when grouper starts up if they are not there
# {valueType: "boolean", required: true}
loader.autoadd.typesAttributes = true

# if a transaction should be used when loading groups.  If not, then
# commits will happen as the group is loaded (and memory usage might be
# less intensive, and caching settings need to be set right)
# {valueType: "boolean", required: true}
loader.use.transactions = false

# if should use threads in the loader for add/remove member
# {valueType: "boolean", required: true}
loader.use.membershipThreads=true

# number of threads to use for each group job (not shared among jobs)
# {valueType: "integer", required: true}
loader.membershipThreadPoolSize=10

# if should use threads in the loader for each group in a group of groups
# {valueType: "boolean", required: true}
loader.use.groupThreads=true

# number of threads to use for each list of groups job (not shared among jobs)
# {valueType: "integer", required: true}
loader.groupThreadPoolSize=20

# if should use threads in incremental loader jobs
# {valueType: "boolean", required: true}
loader.incrementalThreads=true

# number of threads to use in incremental loader jobs (not shared among jobs)
# {valueType: "integer", required: true}
loader.incrementalThreadPoolSize=10

# number of days to retain db logs in table grouperloader_log.  -1 is forever.  default is 7
# {valueType: "integer", required: true}
loader.retain.db.logs.days=7

# number of days to retain db rows in grouper_change_log_entry.  -1 is forever.  default is 14
# {valueType: "integer", required: true}
loader.retain.db.change_log_entry.days=14

# if daemon should remove old values which are multi-assigned if the attribute is single valued
# {valueType: "boolean", required: true}
loader.removeMultiAttributeValuesIfSingleValuedAttribute = true

# if daemon should remove old values which are multi-assigned if the attribute is single valued
# {valueType: "boolean", required: true}
loader.removeMultiAttributeValuesIfSingleValuedAttributeLogOnly = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
# {valueType: "boolean", required: true}
loader.removeMultiAttributeAssignIfSingleAssignAttribute = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
# {valueType: "boolean", required: true}
loader.removeMultiAttributeAssignIfSingleAssignAttributeLogOnly = true


# if you want queries which do not specify subject source to come from a certain
# source, specify here (improves performance so it doesnt search through all sources)
# {valueType: "string"}
default.subject.source.id = 

#if using a sql table, and specifying the name like string, then should the group (in addition to memberships)
# be removed if not used anywhere else?
# {valueType: "boolean", required: true}
loader.sqlTable.likeString.removeGroupIfNotUsed = true

# if using a sql table, and specifying the name like string, then should the group be removed even when the group is member of some other group. 
# loader.sqlTable.likeString.removeGroupIfNotUsed has to be true for this to work
# https://bugs.internet2.edu/jira/browse/GRP-1132
# {valueType: "boolean", required: true}
loader.sqlTable.likeString.removeGroupIfMemberOfAnotherGroup = false

# by default the top folder for an ldap group of groups is the folder where the config group lives.
# set to false if you want to be able to provision groups to anywhere
# {valueType: "boolean", required: true}
loader.ldap.requireTopStemAsStemFromConfigGroup = true

# if you dont specify a groupNameExpression, groups will be loaded into this folder
# if this property doesnt exist, it will be groups:    if it is blank, then there is no top level folder
# e.g. loader:groups
# {valueType: "string"}
loader.ldap.defaultGroupFolder = groups:

# Delimiter used in the example edu.internet2.middleware.grouper.app.loader.ldap.LdapResultsTransformationDelimitedValueExample
# {valueType: "string"}
loader.ldap.resultsTransformationDelimitedValueExampleDelimiter = -

# Comma separated list of stems under which the display name changes in stems are allowed.
# eg: loader.allowStemDisplayNameChangesUnderStems=school:courses:english, school:faculty
# {valueType: "stem", multiple: true}
loader.allowStemDisplayNameChangesUnderStems =

# If a job creates or updates a group, and the job parameters do not compute
# a description, true if a blank description is allowed. If false, the description will
# be set to "{groupExtension} auto-created by grouperLoader".
# {valueType: "boolean", required: false}
loader.allowBlankGroupDescriptions = false

# fix include excludes on each run
# {valueType: "boolean", required: true}
loader.fixIncludeExcludes = false

#potentially delete groups that are no longer in the source system
# {valueType: "boolean", required: true}
loader.deleteGroupsNoLongerInSource = false

############################################
## Auditing lifetimes
############################################

# number of days to retain db rows in grouper_audit_entry with no logged in user (loader, gsh, etc).  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
# audit entries with no logged in user aren't really all that useful.  There is point in time data still.  So removing these shouldn't be a big deal
# {valueType: "integer", required: true}
loader.retain.db.audit_entry_no_logged_in_user.days=-1

# number of days to retain db rows in grouper_audit_entry.  -1 is forever.  suggested is -1 or ten years: 3650
# Some think its ok to remove all audit entries over 10 (or X) years, but will default this 
# to never since even at large institutions there aren't that many records.  
# These are audits for things people do on the UI or WS generally (as a different to records with no logged in user) 
# {valueType: "integer", required: true}
loader.retain.db.audit_entry.days=-1

# number of days to retain db rows for point in time deleted objects.  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
# After you delete an object in grouper, it is still in point in time.  So if you want to know who 
# was in a group a year ago, you need this info
# However, after some time it might be ok to let it go.  So the default is 5 years
# {valueType: "integer", required: true}
loader.retain.db.point_in_time_deleted_objects.days=-1

# number of days after a subfolder (directly in a parent folder) is created that it will be obliterated (deleted) 
# and point in time will be deleted too. 
# "courses" or "anotherLabel" are variables you make up in these examples
# This is optional.  You can automatically obliterate folders *directly in a parent folder* that are a certain age old  e.g. courses.
# so you could delete a term of courses 4 years old if you like.  Note, make sure the loader isn't going to recreate or you will get churn
# Note this can also delete the point in time data as well.
# {valueType: "integer", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.days$"}
#loader.retain.db.folder.courses.days=1825

# delete old folders in this folder
# {valueType: "stem", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.parentFolderName$"}
#loader.retain.db.folder.courses.parentFolderName=my:folder:for:courses

# if also delete point in time for this old folder
# {valueType: "boolean", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.deletePointInTime$"}
#loader.retain.db.folder.courses.deletePointInTime=true

# number of days after a subfolder (directly in a parent folder) is created that it will be obliterated (deleted) 
# and point in time will be deleted too. 
# "courses" or "anotherLabel" are variables you make up in these examples
# This is optional.  You can automatically obliterate folders *directly in a parent folder* that are a certain age old  e.g. courses.
# so you could delete a term of courses 4 years old if you like.  Note, make sure the loader isn't going to recreate or you will get churn
# Note this can also delete the point in time data as well.
# {valueType: "integer", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.days$"}
#loader.retain.db.folder.anotherLabel.days=1825

# delete old folders in this folder
# {valueType: "stem", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.parentFolderName$"}
#loader.retain.db.folder.anotherLabel.parentFolderName=my:folder:for:something

# if also delete point in time for this old folder
# {valueType: "boolean", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.deletePointInTime$"}
#loader.retain.db.folder.anotherLabel.deletePointInTime=false



######################################
## Fail-safe 1 - Each individual group
######################################

# if the loader should check to see too many users were removed, if so, then error out and
# wait for manual intervention
# {valueType: "boolean", required: true}
loader.failsafe.use = false

# if a group has a size less than this (default 200), then make changes including blanking it out 
# {valueType: "integer", required: true}
loader.failsafe.minGroupSize = 200

# if a group with more members than the loader.failsafe.minGroupSize have more than this percent (default 30)  
# removed, then log it as error, fail the job, and don't actually remove the members 
# In order to run the job, an admin would need to change this param in the config, 
# and run the job manually, then change this config back 
# {valueType: "integer", required: true}
loader.failsafe.maxPercentRemove = 30


############################################
## Fail-safe 2 - Group list - managed groups
############################################

# For group lists, if groupLikeString is specified, you can use this fail-safe to prevent too
# many groups from having their memberships cleared out because they are managed by the loader
# (i.e. match the groupLikeString) but don't have memberships in the group query.
# {valueType: "boolean", required: true}
loader.failsafe.groupList.managedGroups.use = false

# Only applicable if the number of managed groups (i.e. match the groupLikeString) that have
# members in Grouper before the loader starts is at least this amount.
# {valueType: "integer", required: true}
loader.failsafe.groupList.managedGroups.minManagedGroups = 200

# If the group list meets the criteria above and the percentage of groups that are managed by
# the loader (i.e. match the groupLikeString) that currently have members in Grouper but 
# wouldn't after the job runs is greater than this percentage, then don't remove members,
# log it as an error and fail the job.  An admin would need to change this param in the config,
# and run the job manually, then change this config back.
# {valueType: "integer", required: true}
loader.failsafe.groupList.managedGroups.maxPercentRemove = 30


#################################
## Performance enhancements
#################################

# if you want to bulk retrieve subjects to add/remove
# {valueType: "boolean", required: true}
loader.bulkLookupSubjects = true

#########################
## Unresolvables
#########################

# If there are unresolvables while loading a group from the source data, the job will still 
# have a result of SUCCESS unless the total membership count (with unresolvables) is 
# greater than or equal to minGroupSize and the percentage of unresolvables is greater than 
# the percent specified, in which case the result will be SUBJECT_PROBLEMS.
# {valueType: "integer", required: true}
loader.unresolvables.minGroupSize = 200

# If there are unresolvables while loading a group from the source data, the job will still 
# have a result of SUCCESS unless the total membership count (with unresolvables) is 
# greater than or equal to minGroupSize and the percentage of unresolvables is greater than 
# the percent specified, in which case the result will be SUBJECT_PROBLEMS.
# {valueType: "integer", required: true}
loader.unresolvables.maxPercentForSuccess = 5


#################################
## DB connections
## specify the db connection with user, pass, url, and driver class
## the string after "db." is the name of the connection, and it should not have
## spaces or other special chars in it
#################################

# specify the db connection with user, pass, url, and driver class
# the string after "db." is the name of the connection, and it should not have
# spaces or other special chars in it
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.user$"}
# db.warehouse.user = mylogin

#note the password can be stored encrypted in an external file
# {valueType: "password", sensitive: true, regex: "^db\\.([^.]+)\\.pass$"}
#db.warehouse.pass = secret

# url for database connections
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.url$"}
#db.warehouse.url = jdbc:mysql://localhost:3306/grouper

# note: you probably dont have to enter a driver, it will detect from URL.  If it
# cant detect, then specify it here
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.driver$"}
#db.warehouse.driver = 

#optional pooling params, these will default to the grouper.hibernate(.base).properties pooling settings
# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.max_size$"}
#db.warehouse.c3p0.max_size = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.min_size$"}
#db.warehouse.c3p0.min_size = 0

# seconds
# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.timeout$"}
#db.warehouse.c3p0.timeout = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.max_statements$"}
#db.warehouse.c3p0.max_statements = 0

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.idle_test_period$"}
#db.warehouse.c3p0.idle_test_period = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.acquire_increment$"}
#db.warehouse.c3p0.acquire_increment = 1

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.validate$"}
#db.warehouse.c3p0.validate = false

# if the db connections should be pooled (this is new as of 2.3.0.patch)
# {valueType: "boolean", required: true}
grouperLoader.db.connections.pool = true

#################################
## LDAP connections
## specify the ldap connection with user, pass, url
## the string after "ldap." is the ID of the connection, and it should not have
## spaces or other special chars in it.  In this case is it "personLdap"
#################################

# specify the ldap connection with user, pass, url
# the string after "ldap." is the ID of the connection, and it should not have
# spaces or other special chars in it.  In this case is it "personLdap"
#note the URL should start with ldap: or ldaps: if it is SSL.  
#It should contain the server and port (optional if not default), and baseDn, 
#e.g. ldaps://ldapserver.school.edu:636/dc=school,dc=edu
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.url$"}
#ldap.personLdap.url = ldaps://ldapserver.school.edu:636/dc=school,dc=edu

# load this ldaptive config file before the configs here.  load from classpath
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.configFileFromClasspath$"}
#ldap.personLdap.configFileFromClasspath = ldap.personLdap.properties

#optional, if authenticated
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.user$"}
#ldap.personLdap.user = uid=someapp,ou=people,dc=myschool,dc=edu

#optional, if authenticated, note the password can be stored encrypted in an external file
# {valueType: "password", sensitive: true, regex: "^ldap\\.([^.]+)\\.pass$"}
#ldap.personLdap.pass = secret

#optional, if you are using tls, set this to true.  Generally you will not be using an SSL URL to use TLS...
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.tls$"}
#ldap.personLdap.tls = false

#optional, if using sasl
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.saslAuthorizationId$"}
#ldap.personLdap.saslAuthorizationId = 

#optional, if using sasl
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.saslRealm$"}
#ldap.personLdap.saslRealm = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.batchSize$"}
#ldap.personLdap.batchSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.countLimit$"}
#ldap.personLdap.countLimit = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.timeLimit$"}
#ldap.personLdap.timeLimit = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.timeout$"}
#ldap.personLdap.timeout = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.minPoolSize$"}
#ldap.personLdap.minPoolSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.maxPoolSize$"}
#ldap.personLdap.maxPoolSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.validateOnCheckIn$"}
#ldap.personLdap.validateOnCheckIn = 

# validateOnCheckOut defaults to true if all other validate methods are false
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.validateOnCheckOut$"}
#ldap.personLdap.validateOnCheckOut = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "boolean", regex: "^ldap\\.([^.]+)\\.validatePeriodically$"}
#ldap.personLdap.validatePeriodically = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.validateTimerPeriod$"}
#ldap.personLdap.validateTimerPeriod = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.pruneTimerPeriod$"}
#ldap.personLdap.pruneTimerPeriod = 

# if there is a max size limit on ldap server, then this will retrieve results in pages
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.pagedResultsSize$"}
#ldap.personLdap.pagedResultsSize = 

# set to 'follow' if using AD and using paged results size and need this for some reason (generally you shouldnt)
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.referral$"}
#ldap.personLdap.referral = 

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validator$"}
#ldap.personLdap.validator = SearchValidator

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareDn$"}
#ldap.personLdap.validatorCompareDn = ou=people,dc=example,dc=com

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareAttribute$"}
#ldap.personLdap.validatorCompareAttribute = ou

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareValue$"}
#ldap.personLdap.validatorCompareValue = people

# comma-delimited list of classes to process LDAP search results. Useful if AD returns a ranged attribute for large
# groups (e.g., member;range=0-1499); include the GrouperRangeEntryHandler to handle progressive fetching.
# {valueType: "class", mustImplementInterface:"org.ldaptive.handler.Handler", multiple: true, regex: "^ldap\\.([^.]+)\\.searchResultHandlers$"}
#ldap.personLdap.searchResultHandlers=org.ldaptive.handler.DnAttributeEntryHandler,edu.internet2.middleware.grouper.ldap.ldaptive.GrouperRangeEntryHandler

# comma-delimited list of result codes (org.ldaptive.ResultCode) to ignore, e.g. TIME_LIMIT_EXCEEDED, SIZE_LIMIT_EXCEEDED, PARTIAL_RESULTS
# {valueType: "string", multiple: true, regex: "^ldap\\.([^.]+)\\.searchIgnoreResultCodes$"}
#ldap.personLdap.searchIgnoreResultCodes=SIZE_LIMIT_EXCEEDED

##################################
## LDAP loader settings
##################################

# el classes to add to the el context for the EL to calculate subejct ids or group names etc.  
# Comma-separated fully qualified classnamesm will be registered by the non-fully qualified
# uncapitalized classname.  So you register a.b.SomeClass, it will be available by variable: someClass
# {valueType: "class", multiple: true}
loader.ldap.el.classes = 

##################################
## Daemon logging
## When running the daemon log, do you want to log these various things?
##################################

# overall log for a job
# {valueType: "boolean", required: true}
daemon.log.logEnabled_overallLog = true

# subjob log for a job (e.g. if a job manages a lite of groups)
# {valueType: "boolean", required: true}
daemon.log.logEnabled_subjobLog = true

# groups being created or deleted
# {valueType: "boolean", required: true}
daemon.log.logEnabled_groupManagement = true

# memberships being created or deleted
# {valueType: "boolean", required: true}
daemon.log.logEnabled_membershipManagement = true

# if each logger map should have an id
# {valueType: "boolean", required: true}
daemon.log.logIdsEnabled = false



##################################
## Daily report
##################################
#quartz cron-like schedule for daily grouper report, the default is 7am every day: 0 0 7 * * ? 
#leave blank to disable this
# {valueType: "string"}
daily.report.quartz.cron = 

#comma separated email addresses to email the daily report, e.g. a@b.c, b@c.d
# {valueType: "string", multiple: true}
daily.report.emailTo = 

#days on which usdu should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
# {valueType: "string", multiple: true}
daily.report.usdu.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#days on which bad membership finder should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
# {valueType: "string", multiple: true}
daily.report.badMembership.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#if you put a directory here, the daily reports will be saved there, and you can
#link up to a web service or store them or whatever.  e.g. /home/grouper/reports/
# {valueType: "string"}
daily.report.saveInDirectory =

##################################
## enabled / disabled cron
##################################

#quartz cron-like schedule for enabled/disabled daemon.  Note, this has nothing to do with the changelog
#leave blank to disable this, the default is 12:01am, 11:01am, 3:01pm every day: 0 1 0,11,15 * * ? 
# {valueType: "string"}
changeLog.enabledDisabled.quartz.cron = 0 1 0,11,15 * * ?

##################################
## grouper builtin messaging cleanup cron
##################################

#quartz cron-like schedule for grouper messaging daemon.
#leave blank to disable this, the default is every hour, 10 minutes after the hour 
#this daemon does cleanup on the builtin messaging table
# {valueType: "string"}
changeLog.builtinMessagingDaemon.quartz.cron = 0 10 * * * ?

# after three days of not consuming messages, delete them, if -1, dont run this daemon
# {valueType: "integer", required: true}
grouper.builtin.messaging.deleteAllMessagesMoreThanHoursOld = 72

# after three hours of having processed messages, delete them.  Note, if this is -1 just delete when marking processed
# {valueType: "integer", required: true}
grouper.builtin.messaging.deleteProcessedMessagesMoreThanMinutesOld = 180





##################################
## Change log
##################################

# should the change log temp to change log daemon run?  Note, this should be true
# {valueType: "boolean", required: true}
changeLog.changeLogTempToChangeLog.enable = true

#quartz cron-like schedule for change log temp to change log daemon, the default is 50 seconds after every minute: 50 * * * * ?
# {valueType: "string"}
changeLog.changeLogTempToChangeLog.quartz.cron = 

# The max number of changes to send to a change log consumer at one time
# {valueType: "integer", required: true}
changeLog.changeLogConsumerBatchSize = 1000

# Should the change log include flattened memberships?  
# {valueType: "boolean", required: true}
changeLog.includeFlattenedMemberships = true

# Should the change log include flattened privileges?  
# {valueType: "boolean", required: true}
changeLog.includeFlattenedPrivileges = true

# Should the change log include roles that have had permission changes?  
# {valueType: "boolean", required: true}
changeLog.includeRolesWithPermissionChanges = false

# Should the change log include non-flattened (immediate and composite only) memberships?
# {valueType: "boolean", required: true}
changeLog.includeNonFlattenedMemberships = false

# Should the change log include non-flattened (immediate only) privileges?
# {valueType: "boolean", required: true}
changeLog.includeNonFlattenedPrivileges = false

# Once the number of change log updates exceeds this value, the transaction will commit and a new one will be created
# {valueType: "integer", required: true}
changeLog.tooManyChangeLogUpdatesSize = 10000


##################################
## Change log consumers
##################################

# specify the consumers here.  specify the consumer name after the changeLog.consumer. part.  This example is "printTest"
# but it could be "myConsumerName" e.g. changeLog.consumer.myConsumerName.class
# the class must extend edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase
# note see Impl below
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
# changeLog.consumer.printTest.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintTest

# the quartz cron is a cron-like string.  it defaults to every minute on the minute (since the temp to change log job runs
# at 10 seconds to each minute).  it defaults to this: 0 * * * * ?
# though it will stagger each one by 2 seconds.  You can leave this blank
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
# changeLog.consumer.printTest.quartzCron = 

# rules consumer, needed for some of the Grouper rule types to run (e.g. flattenedMembershipRemove, flattenedMembershipAdd)
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase"}
changeLog.consumer.grouperRules.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.RuleConsumer

# rules consumer, needed for some of the Grouper rule types to run (e.g. flattenedMembershipRemove, flattenedMembershipAdd)
# {valueType: "string"}
changeLog.consumer.grouperRules.quartzCron =

# consumer for syncing groups to other groupers
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase"}
changeLog.consumer.syncGroups.class = edu.internet2.middleware.grouper.client.GroupSyncConsumer

# consumer for syncing groups to other groupers
# {valueType: "string"}
changeLog.consumer.syncGroups.quartzCron =


##################################
## Change log consumers based in Impl
## Note, you might want to extend: edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBaseImpl
## this is a higher level change log consumer that does a lot of logic for you
## this class will fire certain events for groups and memberships based on tagged folders or groups
## Note, to use this make an attribute and assign it to (generally) folder(s) or some groups or whatever
## GSH:
## GrouperSession grouperSession = GrouperSession.startRootSession();
## AttributeDef provisioningMarkerAttributeDef = new AttributeDefSave(grouperSession).assignCreateParentStemsIfNotExist(true).assignName("attr:someAttrDef").assignToStem(true).assignToGroup(true).save();
## AttributeDefName provisioningMarkerAttributeName = new AttributeDefNameSave(grouperSession, provisioningMarkerAttributeDef).assignName("attr:provisioningMarker").save()
## Stem parentFolder = StemFinder.findByName(grouperSession, "some:folder", true);
## parentFolder.getAttributeDelegate().assignAttribute(provisioningMarkerAttributeName);
##################################


# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBaseImpl", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
# changeLog.consumer.abc.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintChangeLogConsumer

# note: this name matches the attribute name created in the example above
# {valueType: "attributeDefName", regex: "^changeLog\\.consumer\\.([^.]+)\\.syncAttributeName$"}
# changeLog.consumer.abc.syncAttributeName = attr:provisioningMarker

# quartz cron of consumer
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
# changeLog.consumer.abc.quartzCron =

# defaults to true if not configured
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.retryOnError$"}
# changeLog.consumer.abc.retryOnError = true



##################################
## PSP
##################################

# psp consumer class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.psp.grouper.PspChangeLogConsumer"}
# changeLog.consumer.psp.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger
# {valueType: "string"}
# changeLog.consumer.psp.quartzCron = 0 * * * * ?

# To retry processing a change log entry if an error occurs, set retryOnError to true. Defaults to false.
# {valueType: "boolean", required: true}
# changeLog.consumer.psp.retryOnError = false

# To run full provisioning synchronizations periodically, provide the class name which provides a 'public void fullSync()' method.
# {valueType: "class"}
# changeLog.psp.fullSync.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# Schedule full synchronizations. Defaults to 5 am : 0 0 5 * * ?.
# {valueType: "string"}
# changeLog.psp.fullSync.quartzCron = 0 0 5 * * ?

# Run a full synchronization job at startup. Defaults to false.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.runAtStartup = false

# Omit diff responses from bulk response to conserve memory.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.omitDiffResponses = true

# Omit sync responses from bulk response to conserve memory.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.omitSyncResponses = true




###################################
## XMPP notifications 
## (note, uncomment the consumer class and cron above)
## this will get grouper ws getMembers rest lite xmp: 
## http://anonsvn.internet2.edu/cgi-bin/viewvc.cgi/i2mi/trunk/grouper-ws/grouper-ws/doc/samples/getMembers/WsSampleGetMembersRestLite_xml.txt?view=log
###################################

# general xmpp configuration
# {valueType: "string"}
xmpp.server.host = jabber.school.edu

# xmpp port
# {valueType: "integer", required: true}
xmpp.server.port = 5222

# xmpp username
# {valueType: "string"}
xmpp.user = username

# note, pass can be in an external file with morphstring
# {valueType: "password", sensitive: true}
xmpp.pass = 

# xmpp resource
# {valueType: "string"}
xmpp.resource = grouperServer

###################################
## Rules config
###################################

# when the rules validations and daemons run.  Leave blank to not run
# {valueType: "string"}
rules.quartz.cron = 0 0 7 * * ?

#####################################
## Messaging overall settings for daemon jobs
#####################################

# auto create built in queues, topics, privileges
# {valueType: "boolean", required: true}
loader.messaging.settings.autocreate.objects = true


#####################################
## Messaging listener using the messaging API
## note, change "messagingListener" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
## extends edu.internet2.middleware.grouper.messaging.MessagingListenerBase
## note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
## this listener will just print out messages: edu.internet2.middleware.grouper.messaging.MessagingListenerPrint
#####################################

# messaging listener class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.messaging.MessagingListener", regex: "^messaging\\.listener\\.([^.]+)\\.class$"}
#messaging.listener.messagingListener.class = edu.internet2.middleware.grouper.messaging.MessagingListener

# messaging listener quartz cron
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.quartzCron$"}
#messaging.listener.messagingListener.quartzCron = 0 * * * * ?

# messaging listener messaging system name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.messagingSystemName$"}
#messaging.listener.messagingListener.messagingSystemName = grouperBuiltinMessaging

# messaging listener queue name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.queueName$"}
#messaging.listener.messagingListener.queueName = abc

# messaging listener routing key
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.routingKey$"}
#messaging.listener.messagingListener.routingKey =

# messaging listener exchange type. Valid options are DIRECT, HEADERS, TOPIC, FANOUT
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.exchangeType$"}
#messaging.listener.messagingListener.exchangeType =

# messaging listener number of tries per iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.numberOfTriesPerIteration$"}
#messaging.listener.messagingListener.numberOfTriesPerIteration = 3

# messaging listener polling timeout seconds
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.pollingTimeoutSeconds$"}
#messaging.listener.messagingListener.pollingTimeoutSeconds = 18

# messaging listener sleep seconds in between iterations
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.sleepSecondsInBetweenIterations$"}
#messaging.listener.messagingListener.sleepSecondsInBetweenIterations = 0

# messaging listener max messages to receive at once
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxMessagesToReceiveAtOnce$"}
#messaging.listener.messagingListener.maxMessagesToReceiveAtOnce = 20

# if there are 20 messages to receive at once, then do this 50 times per call max
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxOuterLoops$"}
#messaging.listener.messagingListener.maxOuterLoops = 50

#####################################
## Messaging listener using the change log consumer API
#####################################

# note, change "messagingListenerChangeLogConsumer" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
# keep this class to be MessagingListenerToChangeLogConsumer
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.messaging.MessagingListenerToChangeLogConsumer", regex: "^messaging\\.listener\\.([^.]+)\\.class$"}
#messaging.listener.messagingListenerChangeLogConsumer.class = edu.internet2.middleware.grouper.messaging.MessagingListenerToChangeLogConsumer

# Class extends: edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase", regex: "^messaging\\.listener\\.([^.]+)\\.changeLogConsumerClass$"}
#messaging.listener.messagingListenerChangeLogConsumer.changeLogConsumerClass = edu.internet2.middleware.grouper.messaging.SomethingExtendsChangeLogConsumerBase

# messaging listener quartz cron
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.quartzCron$"}
#messaging.listener.messagingListenerChangeLogConsumer.quartzCron = 0 * * * * ?

# system name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.messagingSystemName$"}
#messaging.listener.messagingListenerChangeLogConsumer.messagingSystemName = grouperBuiltinMessaging

# queue name in messaging system
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.queueName$"}
#messaging.listener.messagingListenerChangeLogConsumer.queueName = abc

# number of tries per iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.numberOfTriesPerIteration$"}
#messaging.listener.messagingListenerChangeLogConsumer.numberOfTriesPerIteration = 3

# polling timeout seconds
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.pollingTimeoutSeconds$"}
#messaging.listener.messagingListenerChangeLogConsumer.pollingTimeoutSeconds = 18

# sleep seconds in between iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.sleepSecondsInBetweenIterations$"}
#messaging.listener.messagingListenerChangeLogConsumer.sleepSecondsInBetweenIterations = 0

# max messages to receive at once
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxMessagesToReceiveAtOnce$"}
#messaging.listener.messagingListenerChangeLogConsumer.maxMessagesToReceiveAtOnce = 20

# max outer loops
# if there are 20 messages to receive at once, then do this 50 times per call max
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxOuterLoops$"}
#messaging.listener.messagingListenerChangeLogConsumer.maxOuterLoops = 50


#####################################
## Messaging integration with change log, send change log entries to a messaging system
#####################################

# note, change "messaging" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerToMessage", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.messaging.class = edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerToMessage

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.messaging.quartzCron = 0 * * * * ?

# system name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messagingSystemName$"}
#changeLog.consumer.messaging.messagingSystemName = grouperBuiltinMessaging

# routing key
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.routingKey$"}
#changeLog.consumer.messaging.routingKey = 

# exchange type. valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.exchangeType$"}
#changeLog.consumer.messaging.exchangeType = 

# queue or topic
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messageQueueType$"}
#changeLog.consumer.messaging.messageQueueType = queue

# queue or topic name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.queueOrTopicName$"}
#changeLog.consumer.messaging.queueOrTopicName = abc


#####################################
## Messaging integration with ESB, send change log entries to a messaging system
#####################################

# note, change "messagingEsb" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
#changeLog.consumer.messagingEsb.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.messagingEsb.quartzCron = 0 * * * * ?

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.messagingEsb.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'

# publishing class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbMessagingPublisher", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$"}
#changeLog.consumer.messagingEsb.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbMessagingPublisher

# messaging system name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messagingSystemName$"}
#changeLog.consumer.messagingEsb.publisher.messagingSystemName = grouperBuiltinMessaging

# routing key
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.routingKey$"}
#changeLog.consumer.messagingEsb.publisher.routingKey = 

# EL replacement definition. groupName is the variable for the name of the group. grouperUtil is the class GrouperUtilElSafe can be used for utility methods. 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.regexRoutingKeyReplacementDefinition$"}
#changeLog.consumer.messagingEsb.regexRoutingKeyReplacementDefinition = ${groupName.replaceFirst('hawaii.edu', 'group.modify').replace(':enrolled', '').replace(':waitlisted', '').replace(':withdrawn', '')}

# replace routing key with periods
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.replaceRoutingKeyColonsWithPeriods$"}
#changeLog.consumer.messagingEsb.replaceRoutingKeyColonsWithPeriods = true

# queue or topic
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.messageQueueType$"}
#changeLog.consumer.messagingEsb.publisher.messageQueueType = queue

# queue or topic name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.queueOrTopicName$"}
#changeLog.consumer.messagingEsb.publisher.queueOrTopicName = abc

# exchange type for rabbitmq. valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.exchangeType$"}
#changeLog.consumer.messagingEsb.publisher.exchangeType = 

#####################################
## ESB integration
#####################################

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.awsJira.quartzCron = 0/15 * * * * ?

# class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.awsJira.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.awsJira.elfilter = event.eventType eq 'MEMBERSHIP_ADD' || event.eventType eq 'MEMBERSHIP_ADD'

# if dont send sensitive data
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.noSensitiveData$"}
#changeLog.consumer.awsJira.noSensitiveData = true

# if you want to encrypt messages, set this to an implementation of edu.internet2.middleware.grouperClient.encryption.GcEncryptionInterface
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.encryptionImplementation$", mustImplementInterface: "edu.internet2.middleware.grouperClient.encryption.GcEncryptionInterface"}
#changeLog.consumer.awsJira.encryptionImplementation = edu.internet2.middleware.grouperClient.encryption.GcSymmetricEncryptAesCbcPkcs5Padding

# this is a key or could be encrypted in a file as well like other passwords
# generate a key with: java -cp grouperClient.jar edu.internet2.middleware.grouperClient.encryption.GcGenerateKey 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.encryptionKey$"}
#changeLog.consumer.awsJira.encryptionKey = abc123

# if you dont want to send the first 4 of the sha hash base 64 of the secret
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.dontSendShaBase64secretFirst4$"}
#changeLog.consumer.awsJira.dontSendShaBase64secretFirst4 = false

# publisher class
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$", mustExtendClass: "edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher"}
#changeLog.consumer.awsJira.publisher.class = edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher

# aws access key
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsAccessKey$"}
#changeLog.consumer.awsJira.publisher.awsAccessKey = ABCXYZ

# aws secret key
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsSecretKey$"}
#changeLog.consumer.awsJira.publisher.awsSecretKey = 123REWQ

# aws region
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsRegion$"}
#changeLog.consumer.awsJira.publisher.awsRegion = US_EAST_1

# aws sns topic arn
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsSnsTopicArn$"}
#changeLog.consumer.awsJira.publisher.awsSnsTopicArn = arn:aws:sns:us-east-1:123:name

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.xmppTest.quartzCron = 

# class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.xmppTest.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.xmppTest.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'

# publisher class
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$", mustExtendClass: "edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher"}
#changeLog.consumer.xmppTest.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbXmppPublisher

# publisher server
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.server$"}
#changeLog.consumer.xmppTest.publisher.server = jabber.school.edu

# {valueType: "integer", required: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.port$"}
#changeLog.consumer.xmppTest.publisher.port = 5222

# user name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.username$"}
#changeLog.consumer.xmppTest.publisher.username = jabberuser

# password
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.password$"}
#changeLog.consumer.xmppTest.publisher.password = /home/whatever/pass/jabberuserEncrypted.pass

# recipient
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.recipient$"}
#changeLog.consumer.xmppTest.publisher.recipient = system1@school.edu

# add subject attributes
# {valueType: "string", multiple: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.addSubjectAttributes$"}
#changeLog.consumer.xmppTest.publisher.addSubjectAttributes = NETID

#note, on the content type header, activemq might need: application/x-www-form-urlencoded
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.contentTypeHeader$"}
#changeLog.consumer.xmppTest.publisher.contentTypeHeader = application/json; charset=utf-8

#note, on the stringRequestEntityPrefix, activemq might need: data=
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.stringRequestEntityPrefix$"}
#changeLog.consumer.xmppTest.publisher.stringRequestEntityPrefix = 

#note, on the stringRequestEntityContentType, activemq might need: application/x-www-form-urlencoded
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.stringRequestEntityContentType$"}
#changeLog.consumer.xmppTest.publisher.stringRequestEntityContentType = application/json


################################
## Other jobs built-in
## 
## Configure other jobs.
## "jobName" is the name of your job.
## Class must implement org.quartz.Job.
## Priority is optional
##
## For jobs that run by default, you can disable them by setting an empty quartz cron in grouper-loader.properties.
## tableSync jobs should use class: edu.internet2.middleware.grouper.app.tableSync.TableSyncOtherJob
## and include a setting to point to the grouperClient config, if not same: otherJob.<otherJobName>.grouperClientTableSyncConfigKey = key
################################

# Find and fix bad memberships class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.findBadMemberships.class = edu.internet2.middleware.grouper.misc.FindBadMembershipsDaemon

# Find and fix bad memberships cron
# {valueType: "string"}
otherJob.findBadMemberships.quartzCron = 0 0 1 * * ?

# Find and fix scheduler issues class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.schedulerCheckDaemon.class = edu.internet2.middleware.grouper.app.loader.GrouperDaemonSchedulerCheck

# Find and fix scheduler issues cron
# {valueType: "string"}
otherJob.schedulerCheckDaemon.quartzCron = 25 0/30 * * * ?

# Atttestation Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.attestationDaemon.class = edu.internet2.middleware.grouper.app.attestation.GrouperAttestationJob

# Atttestation Job cron
# {valueType: "string"}
otherJob.attestationDaemon.quartzCron = 0 0 1 * * ?

# Deprovisioning Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.deprovisioningDaemon.class = edu.internet2.middleware.grouper.app.deprovisioning.GrouperDeprovisioningJob

# Deprovisioning Job cron
# {valueType: "string"}
otherJob.deprovisioningDaemon.quartzCron = 0 0 2 * * ?

# Object Type Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperObjectTypeDaemon.class = edu.internet2.middleware.grouper.app.grouperTypes.GrouperObjectTypesJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperObjectTypeDaemon.quartzCron = 0 0 3 * * ?

# Provisioning Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperProvisioningDaemon.class = edu.internet2.middleware.grouper.app.provisioning.GrouperProvisioningJob

# Provisioning Job cron
# {valueType: "string"}
otherJob.grouperProvisioningDaemon.quartzCron = 0 0 4 * * ?

# Run upgrade tasks
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.upgradeTasks.class = edu.internet2.middleware.grouper.app.upgradeTasks.UpgradeTasksJob

# Run upgrade tasks cron
# {valueType: "string"}
otherJob.upgradeTasks.quartzCron = 5 25 * * * ?

# reports clear Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperReportClearDaemon.class = edu.internet2.middleware.grouper.app.reports.GrouperReportClearJob

# reports clear Job cron
# {valueType: "string"}
otherJob.grouperReportClearDaemon.quartzCron = 0 0 3 * * ?

# Workflow daemon that updates instances and send emails
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperWorkfowDaemon.class = edu.internet2.middleware.grouper.app.workflow.GrouperWorkflowDaemonJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperWorkfowDaemon.quartzCron = 0 0/5 * ? * * *

# Workflow reminder email daemon
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperWorkfowReminderDaemon.class = edu.internet2.middleware.grouper.app.workflow.GrouperWorkflowReminderEmailJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperWorkfowReminderDaemon.quartzCron = 0 0 4 * * ? 


################################
## Other jobs
## 
## Configure other jobs.
## "jobName" is the name of your job.
## Class must implement org.quartz.Job.  Should extend edu.internet2.middleware.grouper.app.loader.OtherJobBase
## Priority is optional
## see edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob as an example
##
################################

# other job class
# {valueType: "class", regex: "^otherJob.([^.]+).class$", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
# otherJob.jobName.class = 

# other job quartz cron
# {valueType: "string", regex: "^otherJob.([^.]+).quartzCron$"}
# otherJob.jobName.quartzCron = 

# other job priority (optional)
# {valueType: "integer", regex: "^otherJob.([^.]+).priority$"}
# otherJob.jobName.priority =


#####################################
## Object Type Job
#####################################
otherJob.grouperObjectTypeDaemon.class = edu.internet2.middleware.grouper.app.grouperTypes.GrouperObjectTypesJob
otherJob.grouperObjectTypeDaemon.quartzCron = 0 0 3 * * ?


#####################################
## Message to WS Daemon Job
#####################################

# message to ws daemon job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
#otherJob.messageConsumerDaemon.class = edu.internet2.middleware.grouper.app.messaging.MessageConsumerDaemon

# message to ws daemon job cron
# {valueType: "string"}
#otherJob.messageConsumerDaemon.quartzCron = 0 * * ? * *

# there can be multiple entries, "wsMessagingBridge" is the name of this one, change that for each config section
# the messaging system name must correspond to a messaging system in the grouper.client.properties
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messagingSystemName$"}
# grouper.messaging.wsMessagingBridge.messagingSystemName = rabbitMqMessaging

# the queue or topic to check
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messagingSystemName$"}
#grouper.messaging.wsMessagingBridge.queueOrTopicName = sampleWsMessagingQueue

# routingKey is only valid for rabbitmq; for others, it's ignored
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.routingKey$"}
#grouper.messaging.wsMessagingBridge.routingKey = 

# exchangeType is only valid for rabbitmq; for others, it's ignored. Valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", required: false, regex: "^grouper\\.messaging\\.([^.]+)\\.exchangeType$"}
#grouper.messaging.wsMessagingBridge.exchangeType = 

# if this is a "queue" or "topic", generally it will be queue
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messageQueueType$"}
#grouper.messaging.wsMessagingBridge.messageQueueType = queue

# the source id of the source of the user to act as
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.actAsSubjectSourceId$"}
#grouper.messaging.wsMessagingBridge.actAsSubjectSourceId = g:isa

# the subject id of the user to act as
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.actAsSubjectId$"}
#grouper.messaging.wsMessagingBridge.actAsSubjectId = GrouperSystem
 
# the long polling seconds, listen to the queue for this many seconds for messages
# {valueType: "integer", required: true, regex: "^grouper\\.messaging\\.([^.]+)\\.longPollingSeconds$"}
#grouper.messaging.wsMessagingBridge.longPollingSeconds = 20

# grouper ws url
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.url$"}
#grouper.messaging.wsMessagingBridge.ws.url =

# grouper ws username
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.username$"}
#grouper.messaging.wsMessagingBridge.ws.username = 

# grouper ws password
# {valueType: "password", sensitive: true, regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.password$"}
#grouper.messaging.wsMessagingBridge.ws.password = 

#####################################################
## TIER Instrumentation daemon - send stats to TIER.
#####################################################

# set this to enable the instrumentation
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase"}
otherJob.tierInstrumentationDaemon.class = edu.internet2.middleware.grouper.instrumentation.TierInstrumentationDaemon

# cron string
# {valueType: "string"}
otherJob.tierInstrumentationDaemon.quartzCron = 0 0 2 * * ?

# collector url
# {valueType: "string"}
otherJob.tierInstrumentationDaemon.collectorUrl = http://collector.testbed.tier.internet2.edu:5001

############################
## Incremental loader jobs
############################

# incremental loader job class
# {valueType: "class", regex: "^otherJob.([^.]+).class$", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob"}
# otherJob.incrementalLoader1.class = edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob

# incremental loader job cron
# {valueType: "string", regex: "^otherJob.([^.]+).quartzCron$"}
# otherJob.incrementalLoader1.quartzCron = 0 * * * * ?

# incremental loader job database name
# {valueType: "string", regex: "^otherJob.([^.]+).databaseName$"}
# otherJob.incrementalLoader1.databaseName=warehouse

# incremental loader job table name
# {valueType: "string", regex: "^otherJob.([^.]+).tableName$"}
# otherJob.incrementalLoader1.tableName=myincrementaltable

# incremental loader full sync threshold
# If there are more than this many changes for a single loader job, then invoke the full sync instead.  This could improve performance but also handle fail safe which isn't part of the incremental sync.
# {valueType: "integer", regex: "^otherJob.([^.]+).fullSyncThreshold$"}
# otherJob.incrementalLoader1.fullSyncThreshold=100

# whether subject lookups in the data source should be case insensitive.  only applicable for sql loader jobs.  note, if true, for some databases (e.g. oracle), you may need a function based index in your data source for the function "lower" for better performance
# {valueType: "boolean", regex: "^otherJob.([^.]+).caseInsensitiveSubjectLookupsInDataSource$"}
# otherJob.incrementalLoader1.caseInsensitiveSubjectLookupsInDataSource=false


#############
## Quartz settings
#############

# quartz schedule instance name
# {valueType: "string", required: true}
org.quartz.scheduler.instanceName = DefaultQuartzScheduler

# quartz scheduler instnace id
# {valueType: "string", required: true}
org.quartz.scheduler.instanceId = AUTO

# quartz scheduler rmi export
# {valueType: "boolean", required: true}
org.quartz.scheduler.rmi.export = false

# quartz scheduler rmi proxy
# {valueType: "boolean", required: true}
org.quartz.scheduler.rmi.proxy = false

# quartz scheduler wrap job executiong transaction
# {valueType: "boolean", required: true}
org.quartz.scheduler.wrapJobExecutionInUserTransaction = false

# quartz scheduler thread pool class
# {valueType: "class", required: true, mustImplementInterface: "org.quartz.spi.ThreadPool"}
org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool

# quartz scheduler thread count
# {valueType: "integer", required: true}
org.quartz.threadPool.threadCount = 10

# quartz scheduler thread priority
# {valueType: "integer", required: true}
org.quartz.threadPool.threadPriority = 5

# quartz scheduler threads inherit context class
# {valueType: "boolean", required: true}
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true

# quartz scheduler misfire threshold
# {valueType: "integer", required: true}
org.quartz.jobStore.misfireThreshold = 60000

# quartz scheduler jobstore class
# {valueType: "class", required: true, mustImplementInterface: "org.quartz.spi.JobStore"}
org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX

# quartz scheduler data source
# {valueType: "string"}
org.quartz.jobStore.dataSource = myDS

# quartz scheduler table prefix
# {valueType: "string"}
org.quartz.jobStore.tablePrefix = grouper_QZ_

# quartz scheduler is clustered
# {valueType: "boolean", required: true}
org.quartz.jobStore.isClustered = true

# quartz scheduler check in interval
# {valueType: "integer", required: true}
org.quartz.jobStore.clusterCheckinInterval = 20000

# quartz scheduler max connections
# {valueType: "integer", required: true}
org.quartz.dataSource.myDS.maxConnections = 5

# quartz scheduler validation query
# {valueType: "string"}
org.quartz.dataSource.myDS.validationQuery = select id from grouper_ddl

# automatically determined but can override
# {valueType: "class"}
org.quartz.jobStore.driverDelegateClass =

# automatically determined based on hibernate configuration but can override
# {valueType: "class"}
org.quartz.dataSource.myDS.driver =

# quartz scheduler my ds url
# {valueType: "string"}
org.quartz.dataSource.myDS.URL =

# quartz scheduler my ds user
# {valueType: "string"}
org.quartz.dataSource.myDS.user =

# quartz scheduler my ds pass
# {valueType: "password", sensitive: true}
org.quartz.dataSource.myDS.password =


# Quartz seems to have issues where sometimes a job is running twice at the same time, usually after a misfire.
# We have our own check to make sure jobs don't overlap based on data in the grouper_loader_log table if a job's status is STARTED.
# However, if the daemon is killed, it may be stuck on the STARTED state until the row is deleted.  So we'll consider a job's
# STARTED state to be invalid if it hasn't been updated in the number of seconds below.
# {valueType: "integer", required: true}
loader.assumeJobKilledIfNoUpdateInSeconds=300
